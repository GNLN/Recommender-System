<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>eda - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"defaultInteractivePricePerDBU":0.4,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"maxCustomTags":45,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":true,"num_gpus":0,"spark_heap_memory":20396,"instance_type_id":"r3.xlarge","node_type_id":"r3.xlarge","description":"r3.xlarge","support_cluster_tags":true,"container_memory_mb":25495,"node_instance_type":{"instance_type_id":"r3.xlarge","provider":"AWS","compute_units":13.0,"number_of_ips":15,"local_disks":1,"reserved_compute_units":3.64,"memory_mb":31232,"num_cores":4,"reserved_memory_mb":4800},"memory_mb":31232,"is_hidden":false,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":44632,"instance_type_id":"r3.2xlarge","node_type_id":"r3.2xlarge","description":"r3.2xlarge","support_cluster_tags":true,"container_memory_mb":55790,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","compute_units":26.0,"number_of_ips":15,"local_disks":1,"reserved_compute_units":3.64,"memory_mb":62464,"num_cores":8,"reserved_memory_mb":4800},"memory_mb":62464,"is_hidden":false,"category":"Memory Optimized","num_cores":8.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":93104,"instance_type_id":"r3.4xlarge","node_type_id":"r3.4xlarge","description":"r3.4xlarge","support_cluster_tags":true,"container_memory_mb":116380,"node_instance_type":{"instance_type_id":"r3.4xlarge","provider":"AWS","compute_units":52.0,"number_of_ips":30,"local_disks":1,"reserved_compute_units":3.64,"memory_mb":124928,"num_cores":16,"reserved_memory_mb":4800},"memory_mb":124928,"is_hidden":false,"category":"Memory Optimized","num_cores":16.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":190048,"instance_type_id":"r3.8xlarge","node_type_id":"r3.8xlarge","description":"r3.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":237560,"node_instance_type":{"instance_type_id":"r3.8xlarge","provider":"AWS","compute_units":104.0,"number_of_ips":30,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":249856,"num_cores":32,"reserved_memory_mb":4800},"memory_mb":249856,"is_hidden":false,"category":"Memory Optimized","num_cores":32.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":8079,"instance_type_id":"c3.2xlarge","node_type_id":"c3.2xlarge","description":"c3.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":10099,"node_instance_type":{"instance_type_id":"c3.2xlarge","provider":"AWS","compute_units":28.0,"number_of_ips":15,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":15360,"num_cores":8,"reserved_memory_mb":4800},"memory_mb":15360,"is_hidden":false,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":19998,"instance_type_id":"c3.4xlarge","node_type_id":"c3.4xlarge","description":"c3.4xlarge","support_cluster_tags":true,"container_memory_mb":24998,"node_instance_type":{"instance_type_id":"c3.4xlarge","provider":"AWS","compute_units":55.0,"number_of_ips":30,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":30720,"num_cores":16,"reserved_memory_mb":4800},"memory_mb":30720,"is_hidden":false,"category":"Compute Optimized","num_cores":16.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":43837,"instance_type_id":"c3.8xlarge","node_type_id":"c3.8xlarge","description":"c3.8xlarge","support_cluster_tags":true,"container_memory_mb":54796,"node_instance_type":{"instance_type_id":"c3.8xlarge","provider":"AWS","compute_units":108.0,"number_of_ips":30,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":61440,"num_cores":32,"reserved_memory_mb":4800},"memory_mb":61440,"is_hidden":false,"category":"Compute Optimized","num_cores":32.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":20396,"instance_type_id":"i2.xlarge","node_type_id":"i2.xlarge","description":"i2.xlarge","support_cluster_tags":true,"container_memory_mb":25495,"node_instance_type":{"instance_type_id":"i2.xlarge","provider":"AWS","compute_units":14.0,"number_of_ips":15,"local_disks":1,"reserved_compute_units":3.64,"memory_mb":31232,"num_cores":4,"reserved_memory_mb":4800},"memory_mb":31232,"is_hidden":false,"category":"Storage Optimized","num_cores":4.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":44632,"instance_type_id":"i2.2xlarge","node_type_id":"i2.2xlarge","description":"i2.2xlarge","support_cluster_tags":true,"container_memory_mb":55790,"node_instance_type":{"instance_type_id":"i2.2xlarge","provider":"AWS","compute_units":27.0,"number_of_ips":15,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":62464,"num_cores":8,"reserved_memory_mb":4800},"memory_mb":62464,"is_hidden":false,"category":"Storage Optimized","num_cores":8.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":93104,"instance_type_id":"i2.4xlarge","node_type_id":"i2.4xlarge","description":"i2.4xlarge","support_cluster_tags":true,"container_memory_mb":116380,"node_instance_type":{"instance_type_id":"i2.4xlarge","provider":"AWS","compute_units":53.0,"number_of_ips":30,"local_disks":4,"reserved_compute_units":3.64,"memory_mb":124928,"num_cores":16,"reserved_memory_mb":4800},"memory_mb":124928,"is_hidden":false,"category":"Storage Optimized","num_cores":16.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":0,"spark_heap_memory":190048,"instance_type_id":"i2.8xlarge","node_type_id":"i2.8xlarge","description":"i2.8xlarge","support_cluster_tags":true,"container_memory_mb":237560,"node_instance_type":{"instance_type_id":"i2.8xlarge","provider":"AWS","compute_units":104.0,"number_of_ips":30,"local_disks":8,"reserved_compute_units":3.64,"memory_mb":249856,"num_cores":32,"reserved_memory_mb":4800},"memory_mb":249856,"is_hidden":false,"category":"Storage Optimized","num_cores":32.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":1,"spark_heap_memory":44632,"instance_type_id":"p2.xlarge","node_type_id":"p2.xlarge","description":"p2.xlarge (beta)","support_cluster_tags":true,"container_memory_mb":55790,"node_instance_type":{"instance_type_id":"p2.xlarge","provider":"AWS","compute_units":12.0,"number_of_ips":15,"local_disks":0,"reserved_compute_units":3.64,"gpus":1,"memory_mb":62464,"num_cores":4,"reserved_memory_mb":4800},"memory_mb":62464,"is_hidden":false,"category":"GPU Accelerated","num_cores":4.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":8,"spark_heap_memory":383936,"instance_type_id":"p2.8xlarge","node_type_id":"p2.8xlarge","description":"p2.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":479920,"node_instance_type":{"instance_type_id":"p2.8xlarge","provider":"AWS","compute_units":94.0,"number_of_ips":30,"local_disks":0,"reserved_compute_units":3.64,"gpus":8,"memory_mb":499712,"num_cores":32,"reserved_memory_mb":4800},"memory_mb":499712,"is_hidden":false,"category":"GPU Accelerated","num_cores":32.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":true,"num_gpus":16,"spark_heap_memory":577824,"instance_type_id":"p2.16xlarge","node_type_id":"p2.16xlarge","description":"p2.16xlarge (beta)","support_cluster_tags":true,"container_memory_mb":722280,"node_instance_type":{"instance_type_id":"p2.16xlarge","provider":"AWS","compute_units":188.0,"number_of_ips":30,"local_disks":0,"reserved_compute_units":3.64,"gpus":16,"memory_mb":749568,"num_cores":64,"reserved_memory_mb":4800},"memory_mb":749568,"is_hidden":false,"category":"GPU Accelerated","num_cores":64.0,"support_ebs_volumes":true,"is_deprecated":false},{"support_ssh":false,"spark_heap_memory":23800,"instance_type_id":"r3.2xlarge","node_type_id":"memory-optimized","description":"Memory Optimized (legacy)","support_cluster_tags":false,"container_memory_mb":28000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","compute_units":26.0,"number_of_ips":15,"local_disks":1,"reserved_compute_units":3.64,"memory_mb":62464,"num_cores":8,"reserved_memory_mb":4800},"memory_mb":30720,"is_hidden":true,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":false,"is_deprecated":true},{"support_ssh":false,"spark_heap_memory":9702,"instance_type_id":"c3.4xlarge","node_type_id":"compute-optimized","description":"Compute Optimized (legacy)","support_cluster_tags":false,"container_memory_mb":12128,"node_instance_type":{"instance_type_id":"c3.4xlarge","provider":"AWS","compute_units":55.0,"number_of_ips":30,"local_disks":2,"reserved_compute_units":3.64,"memory_mb":30720,"num_cores":16,"reserved_memory_mb":4800},"memory_mb":15360,"is_hidden":true,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":false,"is_deprecated":true}],"default_node_type_id":"r3.xlarge"},"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"zoneInfos":[{"id":"us-west-2a","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2c","isDefault":false}],"enableCustomSpotPricingUIByTier":true,"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":false,"enableMaxConcurrentRuns":true,"enableJobAclsConfig":false,"enableFullTextSearch":true,"enableElasticSparkUI":true,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":true,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"perClusterAutoterminationEnabled":true,"enableNotebookCommandNumbers":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 RC2 (Scala 2.11)","packageLabel":"spark-image-3053719f98bccbb1f0410e1420ee81a22e521a0b43b6f220c318f10d281646ff","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.2.x-scala2.11","displayName":"Spark 2.2 RC2 (Experimental, Scala 2.11)","packageLabel":"spark-image-a89bff416842ec8c30d33a1b5aaf3683d4712ea02d0cb2d0e7fbaabfb1b9d42d","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 RC2 (Scala 2.10)","packageLabel":"spark-image-756e80c1f48863a7b837dca26e0a844bb2f9fe5eddf1fb6c9b69c0cf4a19cb71","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.2.x-scala2.10","displayName":"Spark 2.2 RC2 (Experimental, Scala 2.10)","packageLabel":"spark-image-362326e9095981c5f1c0049a535cc25434770e7b861104e90ebddd37a302dd1f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"enableClusterAutoScaling":true,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":true,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"m4.2xlarge":0.5,"r4.xlarge":1,"m4.4xlarge":0.5,"r4.16xlarge":8,"p2.8xlarge":16,"m4.10xlarge":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"m4.xlarge":0.5,"r4.8xlarge":8,"r4.large":0.5,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"memory-optimized":1,"m4.large":0.5,"p2.16xlarge":24,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":0.5,"c4.8xlarge":4,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":true,"enableNotebookHistoryDiffing":true,"branch":"2.45.449","accountsLimit":-1,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":30,"enableNotebookCommandMode":true,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":false,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","cloud":"AWS","disallowAddingAdmins":false,"enableSparkConfUI":true,"featureTier":"UNKNOWN_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","enableOrgSwitcherUI":false,"clustersLimit":-1,"enableJdbcImport":true,"enableElasticDisk":false,"logfiles":"logfiles/","enableWebappSharding":false,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableMountAclService":true,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"8ddb091aa2afbfbecc4acc012efaaf14343b0ba4","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":false,"enableNewTableUI":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":false,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSpotClusterType":true,"enableSparkPackages":true,"dynamicSparkVersions":true,"enableClusterTagsUIByTier":true,"enableNotebookHistoryUI":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":false,"showDebugCounters":false,"enableInstanceProfilesUI":true,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":true,"enableEBSVolumesUIByTier":true,"enableNewJobClusterEdit":false,"upgradeURL":"","maxAutoterminationMinutes":10000,"autoterminateClustersByDefault":false,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":true,"defaultMemoryPerContainerMB":28000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":false,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":true,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":32,"name":"eda","language":"sql","commands":[{"version":"CommandV1","origId":61,"guid":"5d0ef83b-07e4-4dd0-a7e6-a6a7816ed35d","subtype":"command","commandType":"auto","position":1.5,"command":"%md ###User Dashboard","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1495032889070,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"885ae3af-d86b-4a2f-bc94-7a85fc40c340"},{"version":"CommandV1","origId":57,"guid":"d47ad6ce-b1ea-4ecc-8b8f-4deb4cbe62fe","subtype":"command","commandType":"auto","position":3.0,"command":"SELECT sum(is_booking) AS Bookings, int(month), user_location_country FROM expedia_train where user_location_country like '%$Country%' GROUP BY month, user_location_country ORDER BY month","commandVersion":0,"state":"finished","results":{"type":"table","data":[[2.0,1,"214"],[0.0,1,"219"],[17.0,1,"215"],[1.0,1,"218"],[40.0,2,"215"],[0.0,2,"214"],[0.0,2,"219"],[1.0,2,"218"],[1.0,2,"210"],[1.0,3,"218"],[34.0,3,"215"],[0.0,3,"210"],[6.0,3,"214"],[2.0,4,"214"],[34.0,4,"215"],[0.0,4,"219"],[2.0,4,"218"],[0.0,5,"221"],[11.0,5,"218"],[29.0,5,"215"],[6.0,5,"214"],[1.0,5,"121"],[9.0,6,"214"],[15.0,6,"218"],[32.0,6,"215"],[0.0,7,"217"],[2.0,7,"214"],[1.0,7,"218"],[39.0,7,"215"],[2.0,8,"214"],[17.0,8,"215"],[0.0,8,"218"],[0.0,9,"218"],[9.0,9,"215"],[1.0,9,"210"],[2.0,9,"214"],[8.0,10,"215"],[1.0,10,"218"],[2.0,11,"214"],[2.0,11,"218"],[11.0,11,"215"],[2.0,12,"218"],[10.0,12,"215"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"Bookings","type":"\"double\"","metadata":"{}"},{"name":"month","type":"\"integer\"","metadata":"{}"},{"name":"user_location_country","type":"\"string\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Cancelled","error":null,"workflows":[],"startTime":1495040221572,"submitTime":1495040222044,"finishTime":1495040222712,"collapsed":false,"bindings":{"Country":"21"},"inputWidgets":{},"displayType":"lineChart","width":"956","height":"319","xColumns":["month"],"yColumns":["Bookings"],"pivotColumns":["user_location_country"],"pivotAggregation":"sum","customPlotOptions":{"areaChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"41b90146-ff7c-4025-a4b3-9a8d92d9a570"},{"version":"CommandV1","origId":58,"guid":"dca7d9da-b45f-477c-8fdc-e44dee5e81b2","subtype":"command","commandType":"auto","position":5.0,"command":"SELECT hotel_continent, count(hotel_continent) as Count FROM expedia_train GROUP BY hotel_continent ORDER BY hotel_continent","commandVersion":0,"state":"finished","results":{"type":"table","data":[["0",3875],["2",105837],["3",21202],["4",23462],["5",1416],["6",44295]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"hotel_continent","type":"\"string\"","metadata":"{}"},{"name":"Count","type":"\"long\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Error in SQL statement: AnalysisException: Table or view not found: expedia; line 1 pos 61","error":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table or view not found: expedia; line 1 pos 61\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:465)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$9.applyOrElse(Analyzer.scala:484)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$9.applyOrElse(Analyzer.scala:469)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:60)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:469)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:459)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withFileAccessAudit(SQLExecution.scala:60)\n\tat org.apache.spark.sql.execution.QueryExecution.withFileAccessAudit(QueryExecution.scala:50)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply$mcV$sp(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.SQLExecution$.withFileAccessAudit(SQLExecution.scala:53)\n\tat org.apache.spark.sql.execution.QueryExecution.withFileAccessAudit(QueryExecution.scala:50)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:599)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:82)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:28)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:28)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:116)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1495032892300,"submitTime":1495032889156,"finishTime":1495032893075,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"barChart","width":"660","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"86908618-69c9-4777-9e27-a53f874dea52"},{"version":"CommandV1","origId":67,"guid":"7f62bd98-3a62-468d-a56a-96e14fb0cf5d","subtype":"command","commandType":"auto","position":5.75,"command":"%md ####Hotel Cluster booking across time","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1495032889189,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"68cd5244-884e-41f7-b42c-3eeca2f57a3b"},{"version":"CommandV1","origId":68,"guid":"4d7e4f41-1ba3-400f-8631-05f34ecf89e9","subtype":"command","commandType":"auto","position":6.125,"command":"SELECT hotel_cluster, sum(is_booking) AS Bookings, count(is_booking) AS Views, int(month) FROM expedia_train where hotel_cluster like '%$Hotels%' GROUP BY month, hotel_cluster ORDER BY month","commandVersion":0,"state":"finished","results":{"type":"table","data":[["45",7.0,106,1],["45",19.0,145,2],["45",10.0,143,3],["45",12.0,139,4],["45",9.0,114,5],["45",10.0,139,6],["45",9.0,205,7],["45",6.0,72,8],["45",9.0,64,9],["45",7.0,79,10],["45",5.0,55,11],["45",10.0,74,12]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"hotel_cluster","type":"\"string\"","metadata":"{}"},{"name":"Bookings","type":"\"double\"","metadata":"{}"},{"name":"Views","type":"\"long\"","metadata":"{}"},{"name":"month","type":"\"integer\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1495040284673,"submitTime":1495040285152,"finishTime":1495040285330,"collapsed":false,"bindings":{"Hotels":"45"},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["month"],"yColumns":["Bookings","Views"],"pivotColumns":["hotel_cluster"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"848f6b28-e209-4067-8019-62ecfee910a3"},{"version":"CommandV1","origId":65,"guid":"3648c4c6-89b0-4650-a57e-afd2abd913e7","subtype":"command","commandType":"auto","position":6.5,"command":"%md ####Hotel Recommendation - Basic","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1495032889299,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6582f008-b351-41f2-8efb-9387f2834cb9"},{"version":"CommandV1","origId":63,"guid":"02ee25ac-98a1-4291-8b55-9424fe36e266","subtype":"command","commandType":"auto","position":7.0,"command":"select srch_destination_id, hotel_cluster, ((sum(is_booking)) + 0.15*(Count(is_booking) - sum(is_booking))) as Rating from expedia_train WHERE srch_destination_id like '%$Destination%' GROUP BY srch_destination_id, hotel_cluster order by Rating DESC LIMIT 5","commandVersion":0,"state":"finished","results":{"type":"table","data":[["8250","1",387.4],["8250","45",211.05],["8250","79",196.5],["8250","24",144.25],["8250","54",136.2]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"srch_destination_id","type":"\"string\"","metadata":"{}"},{"name":"hotel_cluster","type":"\"string\"","metadata":"{}"},{"name":"Rating","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Error in SQL statement: ParseException: \nno viable alternative at input '((sum(is_booking)) + 0.15*(Count(is_booking) - sum(is_booking))> w'(line 1, pos 109)\n\n== SQL ==\nselect srch_destination_id, hotel_cluster, ((sum(is_booking)) + 0.15*(Count(is_booking) - sum(is_booking))> w\n-------------------------------------------------------------------------------------------------------------^^^\n","error":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.parser.ParseException: \nno viable alternative at input '((sum(is_booking)) + 0.15*(Count(is_booking) - sum(is_booking))> w'(line 1, pos 109)\n\n== SQL ==\nselect srch_destination_id, hotel_cluster, ((sum(is_booking)) + 0.15*(Count(is_booking) - sum(is_booking))> w\n-------------------------------------------------------------------------------------------------------------^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:196)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:98)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:45)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:52)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:50)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:47)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parse(DatabricksSqlParser.scala:69)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parsePlan(DatabricksSqlParser.scala:47)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:599)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:82)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:28)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:28)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:116)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1495040336305,"submitTime":1495040336778,"finishTime":1495040337242,"collapsed":false,"bindings":{"Destination":"8250"},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"289fab79-a204-44d1-a248-db058e33c7ac"},{"version":"CommandV1","origId":64,"guid":"eb7b9b92-2daf-4c86-8e2a-04c63c88bfdd","subtype":"command","commandType":"auto","position":8.0,"command":"select CHANNEL, srch_destination_id, sum(is_booking) from expedia_train where srch_destination_id like '%$Destination%' group by CHANNEL, srch_destination_id","commandVersion":0,"state":"finished","results":{"type":"table","data":[["9","8268",69.0],["4","8268",3.0],["6","8268",0.0],["5","8268",4.0],["3","8268",7.0],["1","8268",9.0],["2","8268",6.0],["0","8268",14.0],["7","8268",0.0],["8","8268",1.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"CHANNEL","type":"\"string\"","metadata":"{}"},{"name":"srch_destination_id","type":"\"string\"","metadata":"{}"},{"name":"sum(CAST(is_booking AS DOUBLE))","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Error in SQL statement: ParseException: \nextraneous input 'CHANNEL' expecting {<EOF>, ',', 'WHERE', 'GROUP', 'ORDER', 'HAVING', 'LIMIT', 'JOIN', 'CROSS', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'NATURAL', 'LATERAL', 'WINDOW', 'UNION', 'EXCEPT', 'MINUS', 'INTERSECT', 'SORT', 'CLUSTER', 'DISTRIBUTE', 'ANTI'}(line 1, pos 50)\n\n== SQL ==\nselect sum(is_booking) from expedia_train groupby CHANNEL\n--------------------------------------------------^^^\n","error":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.parser.ParseException: \nextraneous input 'CHANNEL' expecting {<EOF>, ',', 'WHERE', 'GROUP', 'ORDER', 'HAVING', 'LIMIT', 'JOIN', 'CROSS', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'NATURAL', 'LATERAL', 'WINDOW', 'UNION', 'EXCEPT', 'MINUS', 'INTERSECT', 'SORT', 'CLUSTER', 'DISTRIBUTE', 'ANTI'}(line 1, pos 50)\n\n== SQL ==\nselect sum(is_booking) from expedia_train groupby CHANNEL\n--------------------------------------------------^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:196)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:98)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:45)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:52)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:50)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:47)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parse(DatabricksSqlParser.scala:69)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parsePlan(DatabricksSqlParser.scala:47)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:599)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:82)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:28)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:28)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:116)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1495040249193,"submitTime":1495040249672,"finishTime":1495040250402,"collapsed":false,"bindings":{"Destination":"8268"},"inputWidgets":{},"displayType":"pieChart","width":"668","height":"319","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b653440-7853-4db1-9a3c-204b60daa36c"},{"version":"CommandV1","origId":248,"guid":"d52ef690-9119-4f24-a5dd-726f7e2f665a","subtype":"command","commandType":"auto","position":11.0,"command":"select sum(is_mobile), sum(is_package) from expedia_train where hotel_country like '%$countryr%' group by hotel_cluster","commandVersion":0,"state":"finished","results":{"type":"table","data":[[230.0,360.0],[183.0,174.0],[173.0,360.0],[193.0,249.0],[168.0,454.0],[242.0,545.0],[250.0,563.0],[389.0,288.0],[246.0,624.0],[280.0,1009.0],[405.0,1239.0],[198.0,379.0],[271.0,673.0],[238.0,583.0],[349.0,571.0],[245.0,385.0],[318.0,317.0],[184.0,473.0],[182.0,481.0],[88.0,134.0],[440.0,1506.0],[314.0,362.0],[367.0,1000.0],[152.0,364.0],[375.0,743.0],[291.0,309.0],[258.0,545.0],[370.0,869.0],[157.0,238.0],[372.0,804.0],[212.0,551.0],[375.0,547.0],[368.0,626.0],[189.0,536.0],[76.0,230.0],[101.0,235.0],[248.0,454.0],[360.0,1149.0],[314.0,728.0],[227.0,507.0],[301.0,353.0],[205.0,497.0],[244.0,314.0],[285.0,395.0],[111.0,224.0],[290.0,544.0],[178.0,319.0],[478.0,1023.0],[162.0,169.0],[241.0,463.0],[329.0,637.0],[149.0,236.0],[238.0,345.0],[151.0,330.0],[339.0,661.0],[214.0,549.0],[236.0,622.0],[76.0,125.0],[221.0,674.0],[174.0,347.0],[292.0,681.0],[176.0,394.0],[277.0,399.0],[440.0,559.0],[297.0,840.0],[145.0,313.0],[223.0,713.0],[192.0,552.0],[283.0,582.0],[109.0,372.0],[210.0,142.0],[63.0,272.0],[298.0,1029.0],[186.0,395.0],[203.0,521.0],[236.0,541.0],[248.0,420.0],[262.0,558.0],[168.0,292.0],[197.0,474.0],[641.0,2869.0],[215.0,273.0],[199.0,117.0],[325.0,661.0],[99.0,335.0],[298.0,583.0],[225.0,258.0],[320.0,547.0],[132.0,130.0],[232.0,1164.0],[707.0,503.0],[221.0,198.0],[314.0,349.0],[19.0,62.0],[211.0,271.0],[224.0,541.0],[199.0,615.0],[295.0,305.0],[181.0,728.0],[147.0,391.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"sum(CAST(is_mobile AS DOUBLE))","type":"\"double\"","metadata":"{}"},{"name":"sum(CAST(is_package AS DOUBLE))","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Error in SQL statement: AnalysisException: expression 'expedia_train.`is_booking`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;;\nAggregate [hotel_cluster#11536], [sum(cast(is_mobile#11521 as double)) AS sum(CAST(is_mobile AS DOUBLE))#505257, is_booking#11531, sum(cast(is_package#11522 as double)) AS sum(CAST(is_package AS DOUBLE))#505258]\n+- Filter hotel_country#11534 LIKE %50%\n   +- SubqueryAlias expedia_train\n      +- Relation[_c0#11512,date_time#11513,site_name#11514,posa_continent#11515,user_location_country#11516,user_location_region#11517,user_location_city#11518,orig_destination_distance#11519,user_id#11520,is_mobile#11521,is_package#11522,channel#11523,srch_ci#11524,srch_co#11525,srch_adults_cnt#11526,srch_children_cnt#11527,srch_rm_cnt#11528,srch_destination_id#11529,srch_destination_type_id#11530,is_booking#11531,cnt#11532,hotel_continent#11533,hotel_country#11534,hotel_market#11535,... 3 more fields] csv\n","error":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: expression 'expedia_train.`is_booking`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;;\nAggregate [hotel_cluster#11536], [sum(cast(is_mobile#11521 as double)) AS sum(CAST(is_mobile AS DOUBLE))#505257, is_booking#11531, sum(cast(is_package#11522 as double)) AS sum(CAST(is_package AS DOUBLE))#505258]\n+- Filter hotel_country#11534 LIKE %50%\n   +- SubqueryAlias expedia_train\n      +- Relation[_c0#11512,date_time#11513,site_name#11514,posa_continent#11515,user_location_country#11516,user_location_region#11517,user_location_city#11518,orig_destination_distance#11519,user_id#11520,is_mobile#11521,is_package#11522,channel#11523,srch_ci#11524,srch_co#11525,srch_adults_cnt#11526,srch_children_cnt#11527,srch_rm_cnt#11528,srch_destination_id#11529,srch_destination_type_id#11530,is_booking#11531,cnt#11532,hotel_continent#11533,hotel_country#11534,hotel_market#11535,... 3 more fields] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.failAnalysis(CheckAnalysis.scala:39)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:60)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(CheckAnalysis.scala:259)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$12.apply(CheckAnalysis.scala:292)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$12.apply(CheckAnalysis.scala:292)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:292)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:60)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply$mcV$sp(QueryExecution.scala:60)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$assertAnalyzed$1.apply(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.SQLExecution$.withFileAccessAudit(SQLExecution.scala:53)\n\tat org.apache.spark.sql.execution.QueryExecution.withFileAccessAudit(QueryExecution.scala:50)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:599)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:82)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:28)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:28)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:116)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:201)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:173)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:168)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:35)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:206)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:35)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:201)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1495037542528,"submitTime":1495037542968,"finishTime":1495037543334,"collapsed":false,"bindings":{"countryr":""},"inputWidgets":{},"displayType":"lineChart","width":"1095","height":"348","xColumns":["<id>"],"yColumns":["sum(CAST(is_package AS DOUBLE))","sum(CAST(is_mobile AS DOUBLE))"],"pivotColumns":[],"pivotAggregation":"avg","customPlotOptions":{"pieChart":[{"key":"donut","value":true}],"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"histogram":[{"key":"bins","value":"20"}],"areaChart":[{"key":"grouped","value":false},{"key":"stacked","value":false},{"key":"100_stacked","value":true}],"lineChart":[],"scatterPlot":[{"key":"loess","value":false},{"key":"bandwidth","value":0.3}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"029c433a-96b0-414f-b959-37bfc6f39457"}],"dashboards":[{"version":"DashboardViewV1","origId":60,"guid":"01ef54c4-74b7-4ebb-9bb0-b93bb90ee091","nuid":"c79fe766-8177-444b-af93-39ec9a5cea6f","title":"EXPEDIA","width":1024,"layoutOption":{"stack":false,"grid":true},"elements":[{"guid":"4e9fe25a-afca-4cde-81f2-4df5446b78df","elementType":"command","elementNUID":"41b90146-ff7c-4025-a4b3-9a8d92d9a570","position":{"width":24,"height":9,"x":0,"y":2,"z":null},"options":{"showTitle":true,"showRunButton":false,"scale":0,"autoScaleImg":false,"title":"Bookings across months by countries","titleAlign":"center"}},{"guid":"62c5d157-f4d8-483c-a127-8893c8ee44c9","elementType":"command","elementNUID":"3b653440-7853-4db1-9a3c-204b60daa36c","position":{"width":24,"height":14,"x":0,"y":11,"z":null},"options":{"showTitle":true,"scale":0,"autoScaleImg":false,"title":"Marketing channel effectiveness","titleAlign":"center"}},{"guid":"6b97fc13-7214-438c-8ab4-e71b05a53d62","elementType":"command","elementNUID":"289fab79-a204-44d1-a248-db058e33c7ac","position":{"width":24,"height":7,"x":0,"y":34,"z":null},"options":{"showTitle":true,"scale":0,"autoScaleImg":false,"title":"Hotel Recommendation: Custom Algorithm","titleAlign":"center"}},{"guid":"b364135d-4a58-46cf-819b-4e7aec9a7f7a","elementType":"command","elementNUID":"848f6b28-e209-4067-8019-62ecfee910a3","position":{"width":24,"height":9,"x":0,"y":25,"z":null},"options":{"showTitle":true,"scale":0,"autoScaleImg":false,"title":"Hotel Cluster Performance","titleAlign":"center"}},{"guid":"f604ec8a-6f1d-4583-a2ab-8e1ced18d2a1","elementType":"command","elementNUID":"885ae3af-d86b-4a2f-bc94-7a85fc40c340","position":{"width":24,"height":2,"x":0,"y":0,"z":null},"options":{"scale":1,"titleAlign":"center","autoScaleImg":false,"showTitle":false}}],"globalVars":{}},{"version":"DashboardViewV1","origId":62,"guid":"262c4fdd-071e-4ba1-aa1a-e9a034b799b4","nuid":"17d981ae-12af-4ea9-9bdc-8caf4be3765b","title":"Untitled","width":1024,"layoutOption":{"stack":false,"grid":true},"elements":[{"guid":"66b04b10-3e54-45ff-9ee3-4d4557aec894","elementType":"command","elementNUID":"41b90146-ff7c-4025-a4b3-9a8d92d9a570","position":{"width":14,"height":9,"x":4,"y":8,"z":null},"options":{"showTitle":true,"scale":0,"autoScaleImg":false,"title":"Booking by country across months","titleAlign":"center"}},{"guid":"6c7eaf45-8384-43be-b774-2a8661e10ed1","elementType":"command","elementNUID":"86908618-69c9-4777-9e27-a53f874dea52","position":{"width":14,"height":5,"x":4,"y":3,"z":null},"options":{"showTitle":true,"scale":0,"autoScaleImg":false,"title":"Distribution of Expedia usage across Continents","titleAlign":"center"}},{"guid":"8cb5513a-1961-4719-97b2-78926f177be5","elementType":"command","elementNUID":"885ae3af-d86b-4a2f-bc94-7a85fc40c340","position":{"width":14,"height":3,"x":4,"y":0,"z":null},"options":null}],"globalVars":{}}],"guid":"85067bc6-5e7f-4661-b63b-67f4739939f7","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
